{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\StrikeWade\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../mnist\\train-images-idx3-ubyte.gz\n",
      "Extracting ../mnist\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../mnist\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../mnist\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division, absolute_import\n",
    "\n",
    "#Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('../mnist', one_hot=True)\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "\n",
    "#Clear TF memory\n",
    "cfg = K.tf.ConfigProto()\n",
    "cfg.gpu_options.allow_growth = True\n",
    "K.set_session(K.tf.Session(config=cfg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-b288b036ae1e>:15: Dataset.from_tensor_slices (from tensorflow.contrib.data.python.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.from_tensor_slices()`.\n",
      "<Dataset shapes: ((784,), (10,)), types: (tf.float32, tf.float64)>\n",
      " \n",
      "<Dataset shapes: ((?, 784), (?, 10)), types: (tf.float32, tf.float64)>\n"
     ]
    }
   ],
   "source": [
    "#Parmeters\n",
    "learning_rate = 0.01\n",
    "num_steps = 1000\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "#Network Parameters\n",
    "n_input = 784\n",
    "n_classes = 10\n",
    "dropout = 0.75 #probability to keep units\n",
    "\n",
    "sess = tf.Session()\n",
    "\n",
    "#Create a tensor dataset from the images and the labels\n",
    "dataset = tf.contrib.data.Dataset.from_tensor_slices((mnist.train.images, mnist.train.labels))\n",
    "print(dataset)\n",
    "print(' ')\n",
    "\n",
    "#Create batches of data\n",
    "dataset = dataset.batch(batch_size)\n",
    "print(dataset)\n",
    "\n",
    "#Create an iterator to go over all the dataset\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "#It is better to use 2 placeholders, to avoid to load all data into memory,\n",
    "#and avoid the 2gb restriction length of a tensor\n",
    "x = tf.placeholder(dtype=tf.float32, shape=[None, n_input])\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None, n_classes])\n",
    "\n",
    "#Init the iterator\n",
    "sess.run(iterator.initializer, feed_dict={x: mnist.train.images, y: mnist.train.labels})\n",
    "\n",
    "#Neural net input\n",
    "X, Y = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'IteratorGetNext:0' shape=(?, 784) dtype=float32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'IteratorGetNext:1' shape=(?, 10) dtype=float64>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create a classic CNN\n",
    "#Create model\n",
    "def conv_net(x, n_classes, dropout, reuse, is_training):\n",
    "    #Define a scope for reusing the variables\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "        #MNIST data input is a 1-D vector of 784 features(28*28)\n",
    "        #Reshape to match picture format [height * width * channel]\n",
    "        #Tensor input become 4-D [batch size * height * width * channel]\n",
    "        x = tf.reshape(tensor=x, shape=[-1, 28, 28, 1])\n",
    "        \n",
    "        #Convolution layer 1 with 32 filters and kernel of 5\n",
    "        conv1 = tf.layers.conv2d(inputs=x, filters=32, kernel_size=5, activation=tf.nn.relu)\n",
    "        #MaxPooling with strides of 2 and kernel size of 2\n",
    "        conv1 = tf.layers.max_pooling2d(inputs=conv1, strides=2, pool_size=2)\n",
    "        \n",
    "        #Convolution layer 2 with 64 filters and kernel of 3\n",
    "        conv2 = tf.layers.conv2d(inputs=conv1, filters=64, kernel_size=3, activation=tf.nn.relu)\n",
    "        #Maxpooling with strides of 2 and kernel size of 2\n",
    "        conv2 = tf.layers.max_pooling2d(inputs=conv2, strides=2, pool_size=2)\n",
    "        \n",
    "        #Flatten the data to a 1-D vector for the fully connected layer\n",
    "        fc1 = tf.contrib.layers.flatten(conv2)\n",
    "        \n",
    "        #Fully connected layer\n",
    "        fc1 = tf.layers.dense(inputs=fc1, units=1024)\n",
    "        #Apply dropout\n",
    "        fc1 = tf.layers.dropout(inputs=fc1, rate=dropout, training=is_training)\n",
    "        \n",
    "        #Output layer, class prediction\n",
    "        out = tf.layers.dense(inputs=fc1, units=n_classes)\n",
    "        #Becasue softmax_cross_entropy_with_logits already apply softmax,\n",
    "        #we only apply softmax to testing network\n",
    "        out = tf.nn.softmax(out) if not is_training else out\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-fd3beba8efbb>:7: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Create graph for training\n",
    "logits_train = conv_net(x=X, n_classes=n_classes, dropout=dropout, reuse=False, is_training=True)\n",
    "#Create graph for testing (not apply dropout)\n",
    "logits_test = conv_net(x=X, n_classes=n_classes, dropout=dropout, reuse=True, is_training=False)\n",
    "\n",
    "#Define loss and optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits_train, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "#Evaluate model(with test logits)\n",
    "correct_pred = tf.equal(tf.argmax(logits_test, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 1, Minibatch Loss= 8.9890, Training Accuracy= 0.0859\n",
      "Step: 100, Minibatch Loss= 0.2783, Training Accuracy= 0.9297\n",
      "Step: 200, Minibatch Loss= 0.2864, Training Accuracy= 0.9297\n",
      "Step: 300, Minibatch Loss= 0.2681, Training Accuracy= 0.9453\n",
      "Step: 400, Minibatch Loss= 0.1516, Training Accuracy= 0.9453\n",
      "Step: 500, Minibatch Loss= 0.2090, Training Accuracy= 0.9531\n",
      "Step: 600, Minibatch Loss= 0.2018, Training Accuracy= 0.9453\n",
      "Step: 700, Minibatch Loss= 0.1181, Training Accuracy= 0.9844\n",
      "Step: 800, Minibatch Loss= 0.1918, Training Accuracy= 0.9766\n",
      "Step: 900, Minibatch Loss= 0.3203, Training Accuracy= 0.9297\n",
      "Step: 1000, Minibatch Loss= 0.1445, Training Accuracy= 0.9766\n",
      "Training Completed!!!\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "sess.run(init)\n",
    "\n",
    "#Training\n",
    "for step in range(1, num_steps+1):\n",
    "    \n",
    "    try:\n",
    "        #Run optimization\n",
    "        sess.run(train_op)\n",
    "    except tf.errors.OutOfRangeError:\n",
    "        #Reload the iterator when it reaches the end of the dataset\n",
    "        sess.run(iterator.initializer, feed_dict={x: mnist.train.images, y: mnist.train.labels})\n",
    "        sess.run(train_op)\n",
    "        \n",
    "    if step % display_step == 0 or step == 1:\n",
    "        loss, acc = sess.run([loss_op, accuracy])\n",
    "        print('Step: %d, Minibatch Loss= %.4f, Training Accuracy= %.4f' % (step, loss, acc))\n",
    "\n",
    "print('Training Completed!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
